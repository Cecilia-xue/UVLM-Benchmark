# UVLM: Underwater Video-Language Benchmark ğŸŒŠ

[ğŸŒ Website](https://yourname.github.io/uvlm-benchmark/) â€¢
[ğŸ¤— Dataset on Hugging Face](https://huggingface.co/your-org/uvlm) â€¢
[ğŸ“„ Paper](https://arxiv.org/abs/xxxx.xxxxx)

UVLM is a benchmark for **underwater video-language understanding**. It contains **2,109 videos**, ~**0.86M frames**, **419 marine species/categories**, and **20 fine-grained tasks** covering both **biological** and **environmental** aspects of underwater scenes.  
This repository provides:
1. dataset structure and example annotations,
2. official evaluation scripts (MCQA + LLM-based),
3. submission format and leaderboard template,
4. a one-line script to download data from Hugging Face.

---

## ğŸ”” News

- 2025-11-10: Initial release of the UVLM benchmark repo.
- 2025-11-10: Dataset published on Hugging Face: https://huggingface.co/your-org/uvlm
- Coming soon: public leaderboard.

---

## Repository Structure

```text
uvlm-benchmark/
â”œâ”€â”€ README.md
â”œâ”€â”€ setup.py                  # optional, to install as a package
â”œâ”€â”€ uvlm_benchmark/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ downloader.py     # download from Hugging Face
â”‚   â”‚   â”œâ”€â”€ dataset.py        # unified dataset loader
â”‚   â”‚   â””â”€â”€ schemas.py        # annotation field definitions
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â”œâ”€â”€ eval_mcqa.py
â”‚   â”‚   â”œâ”€â”€ eval_llm_judge.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ io.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_from_hf.sh   # one-click HF download
â”‚   â””â”€â”€ run_eval_mcqa.sh
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ README.md             # explains real data layout on HF
â”‚   â””â”€â”€ annotations_example.json
â”œâ”€â”€ submissions/
â”‚   â””â”€â”€ sample_results.json
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ index.md              # GitHub Pages (optional)
â””â”€â”€ CITATION.cff

## 8. Citation

If you use UVLM in your research, please cite:

```bibtex
@article{uvlm2025,
  title={UVLM: Benchmarking Video-Language Model for Underwater World Understanding},
  author={XIZHE XUE, Yangzhou, Dawei Yan, lijie tao, Junjie Li, Ying Li, Haokui Zhang, Rong Xiao },
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2026}
}
